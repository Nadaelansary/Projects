# Importing the Dataset from Kaggle

import pandas as pd

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("data400.csv")
df

# Display the Information of the Dataset

df.info()

# Display the Description of the Dataset

df.describe()

# Dropping the User ID Column as it is irrelevant

df.drop(['User ID'], axis = "columns", inplace = True)
df

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import plot_model

# Choose the Input Attributes

input_attributes = ['Age', 'EstimatedSalary']
X = df[input_attributes]

# Choose the Output Attribute

output_attribute = 'Purchased'
y = df[output_attribute]

# Split the Data

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

# Standardize the Input Data

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Implement the Neural Network Model

model = Sequential([
    Dense(units = 64, activation = 'relu', input_dim = X_train_scaled.shape[1]),
    Dense(units = 1, activation = 'sigmoid')
])

model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

# Train the Neural Network Model

model.fit(X_train_scaled, y_train, epochs = 50, batch_size = 32, validation_data = (X_test_scaled, y_test))

# Evaluate the Neural Network Model

y_pred = model.predict(X_test_scaled)
y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]

print("\n Classification Report:")
print(classification_report(y_test, y_pred_binary))

print("\n Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_binary))

# Visualize the Neural Network Model

print("\n")
plot_model(model, to_file = 'Neural_Network_Model.png', show_shapes = True, show_layer_names = False)
